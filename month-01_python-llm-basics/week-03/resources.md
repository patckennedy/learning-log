# ğŸ“š Week 3 â€“ Resources (Quick Reference)

This week is all about **getting my first LLM setup running** and making my very first calls.  
These are the main things Iâ€™m using to learn and practice:

---

## ğŸ”§ Environments
- Basics of virtual environments (keeping projects clean and separate).  
- Using `.env` files to store API keys safely (never commit these to GitHub).  
- Anaconda setup for managing Python + LLM packages.  

---

## ğŸ’» Local LLM (Ollama)
- Install Ollama on my machine.  
- Run a small model locally to test (so I donâ€™t rely only on cloud APIs).  
- Learn how local models differ from API-based models.  

---

## ğŸŒ API Calls
- Quickstart examples with **OpenAI** (GPT-style models).  
- Quickstart examples with **Hugging Face Inference API**.  
- Note differences: setup, latency, and cost.  

---

## ğŸ§  Core Concepts
- **Transformers** â†’ how models â€œpay attentionâ€ to words in context.  
- **Parameters** â†’ the â€œknobsâ€ that make a model powerful (size = capability).  
- **Context Window** â†’ the memory limit of the model during a single request.  

---

## ğŸ“– Learning Links
- **Course**: [Udemy â€“ LLM Engineering: Master AI, Large Language Models & Agents](https://www.udemy.com/course/llm-engineering-master-ai-and-large-language-models/)  
- **Extra**: [Kaggle â€“ How Models Work](https://www.kaggle.com/code/dansbecker/how-models-work)  

---

âœï¸ _Personal Note:_  
As I go, Iâ€™ll add any commands, fixes, or side tutorials that actually helped me.  
The goal is to make this **my quick grab-and-go reference**, not a textbook.
