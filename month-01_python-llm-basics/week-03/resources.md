# 📚 Week 3 – Resources (Quick Reference)

This week is all about **getting my first LLM setup running** and making my very first calls.  
These are the main things I’m using to learn and practice:

---

## 🔧 Environments
- Basics of virtual environments (keeping projects clean and separate).  
- Using `.env` files to store API keys safely (never commit these to GitHub).  
- Anaconda setup for managing Python + LLM packages.  

---

## 💻 Local LLM (Ollama)
- Install Ollama on my machine.  
- Run a small model locally to test (so I don’t rely only on cloud APIs).  
- Learn how local models differ from API-based models.  

---

## 🌐 API Calls
- Quickstart examples with **OpenAI** (GPT-style models).  
- Quickstart examples with **Hugging Face Inference API**.  
- Note differences: setup, latency, and cost.  

---

## 🧠 Core Concepts
- **Transformers** → how models “pay attention” to words in context.  
- **Parameters** → the “knobs” that make a model powerful (size = capability).  
- **Context Window** → the memory limit of the model during a single request.  

---

## 📖 Learning Links
- **Course**: [Udemy – LLM Engineering: Master AI, Large Language Models & Agents](https://www.udemy.com/course/llm-engineering-master-ai-and-large-language-models/)  
- **Extra**: [Kaggle – How Models Work](https://www.kaggle.com/code/dansbecker/how-models-work)  

---

✏️ _Personal Note:_  
As I go, I’ll add any commands, fixes, or side tutorials that actually helped me.  
The goal is to make this **my quick grab-and-go reference**, not a textbook.
